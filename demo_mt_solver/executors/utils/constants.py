import os
if os.path.exists("/data/publicdata/pretrain"):
    PRETRAIN_DIR = "/data/publicdata/pretrain" # 方便本地测试
else:
    PRETRAIN_DIR = "/app/publicdata/pretrain"
PRETRAIN_MODEL_PATH = {
    # EN
    "BERT": f'{PRETRAIN_DIR}/bert-base-uncased',
    "RoBERTa": f'{PRETRAIN_DIR}/roberta_base',
    "RoBERTa_large": f'{PRETRAIN_DIR}/roberta-large',
    "DistilBERT": f'{PRETRAIN_DIR}/distilbert-base-uncased',
    "ALBERT": f'{PRETRAIN_DIR}/albert-base-v2',
    "GPT": f'{PRETRAIN_DIR}/openai-gpt',
    "GPT2": f'{PRETRAIN_DIR}/gpt2',
    "CTRL": f'{PRETRAIN_DIR}/ctrl',
    "T5": f'{PRETRAIN_DIR}/t5-base',
    "BART": f'{PRETRAIN_DIR}/bart-base',
    "MBART": f'{PRETRAIN_DIR}/tiny-mbart',
    "Longformer": f'{PRETRAIN_DIR}/longformer-base-4096',
    "LayoutLM": f'{PRETRAIN_DIR}/layoutlm-base-uncased',
    "XLMRoBRETa": f'{PRETRAIN_DIR}/xlm-roberta-base',
    "XLNet": f'{PRETRAIN_DIR}/xlnet-base-cased',
    "DeBERTa": f'{PRETRAIN_DIR}/deberta-base',
    "SqueezeBERT": f'{PRETRAIN_DIR}/squeezebert-uncased',
    "MobileBERT": f'{PRETRAIN_DIR}/mobilebert-uncased',
    "BERT_Review": f'{PRETRAIN_DIR}/BERT_Review',
    "BERT_Legal": f'{PRETRAIN_DIR}/legal-bert-base-uncased',
    "BERT_Biomedical": f'{PRETRAIN_DIR}/BiomedNLP-PubMedBERT-base-uncased-abstract',
    "BERT_Bioclinical": f'{PRETRAIN_DIR}/Bio_ClinicalBERT',
    "BERT_Conversational": f'{PRETRAIN_DIR}/bert-base-cased-conversational',
    "BERT_Code": f'{PRETRAIN_DIR}/codebert-base',
    "BERT_Sports": f'{PRETRAIN_DIR}/SportsBERT',
    "RoBERTa_Financial": f'{PRETRAIN_DIR}/financial_roberta',
    "BERT_Science": f'{PRETRAIN_DIR}/scibert_scivocab_cased',
    "BERT_CovidScience": f'{PRETRAIN_DIR}/COVID-SciBERT',
    "BERT_Tweet": f'{PRETRAIN_DIR}/bertweet-base',
    "BERT_CovidTweet": f'{PRETRAIN_DIR}/bertweet-covid19-base-uncased',
    "BERT_Contracts": f'{PRETRAIN_DIR}/bert-base-uncased-contracts',
    "BERT_Biology": f'{PRETRAIN_DIR}/biobert-v1.1',
    "BERT_Chemistry": f'{PRETRAIN_DIR}/ChemBERTa_zinc250k_v2_40k',
    "ernie-2.0-en": f'{PRETRAIN_DIR}/ernie-2.0-en',
    "ernie-2.0-large-en": f'{PRETRAIN_DIR}/ernie-2.0-large-en',

    # ZH
    "BERT_zh": f'{PRETRAIN_DIR}/bert-base-chinese',
    "BERT_WWM": f'{PRETRAIN_DIR}/chinese-bert-wwm-ext',
    "BERT_Multi": f'{PRETRAIN_DIR}/bert-base-zh-cased',
    "RoBERTa_zh": f'{PRETRAIN_DIR}/roberta_chinese_base',
    "RoBERTa_WWM": f'{PRETRAIN_DIR}/chinese-roberta-wwm-ext',
    "TinyRoBERTa": f'{PRETRAIN_DIR}/roberta_chinese_clue_tiny',
    "ALBERT_zh": f'{PRETRAIN_DIR}/albert_chinese_base',
    "TinyALBERT": f'{PRETRAIN_DIR}/albert_chinese_tiny',
    "LargeALBERT": f'{PRETRAIN_DIR}/albert_chinese_xlarge',
    "ELECTRA": f'{PRETRAIN_DIR}/chinese-electra-small-discriminator',
    "ERNIE": f'{PRETRAIN_DIR}/ernie-1.0',
    "RBT3": f'{PRETRAIN_DIR}/rbt3',
    "GPT2": f'{PRETRAIN_DIR}/gpt2-base-chinese',
    "BERT_Guwen": f'{PRETRAIN_DIR}/guwenbert-base',
    "LargeELECTRA_Legal": f'{PRETRAIN_DIR}/chinese-legal-electra-large-discriminator',
    "ELECTRA_Legal": f'{PRETRAIN_DIR}/chinese-legal-electra-base-discriminator',
    "SmallELECTRA_Legal": f'{PRETRAIN_DIR}/chinese-legal-electra-small-discriminator',
    "MacBERT_base": f'{PRETRAIN_DIR}/chinese-macbert-base',
    "MacBERT_large": f'{PRETRAIN_DIR}/chinese-macbert-large',
    "ernie-gram": f'{PRETRAIN_DIR}/ernie-gram',
    "chinese-roberta-wwm-ext": f'{PRETRAIN_DIR}/chinese-roberta-wwm-ext',
    "chinese-roberta-wwm-ext-large": f'{PRETRAIN_DIR}/chinese-roberta-wwm-ext-large',
}